{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjnWEZ0blHHuXFM2Viqgbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashasvi-S-Khade/CV/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGNvDkwKNtFa",
        "outputId": "17f38be4-53e5-4669-c8a6-445cb78ab02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.38-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.38 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.27.2 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit_lottie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmLiFCw-P7xK",
        "outputId": "4a973da5-4d58-449a-f7ce-2cc0d98f8e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit_lottie\n",
            "  Downloading streamlit_lottie-0.0.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit_lottie) (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit_lottie) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (5.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (3.1.38)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_lottie) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_lottie) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit_lottie) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit_lottie) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit_lottie) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_lottie) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_lottie) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_lottie) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_lottie) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_lottie) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_lottie) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_lottie) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_lottie) (0.10.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit_lottie) (0.1.2)\n",
            "Installing collected packages: streamlit_lottie\n",
            "Successfully installed streamlit_lottie-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile index.py\n",
        "\n",
        "import requests\n",
        "import streamlit as st\n",
        "from streamlit_lottie import st_lottie\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from inceptionV3 import deep_dream_inception\n",
        "from resNet50 import deep_dream_resNet50\n",
        "from mobileNet import deep_dream_mobileNet\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Deep Dream\", page_icon=\":nazar_amulet:\", layout=\"wide\")\n",
        "\n",
        "def get_layer_info(model, layer_number):\n",
        "    \"\"\"\n",
        "    Retrieve information about the selected layer.\n",
        "    \"\"\"\n",
        "    layer = model.layers[layer_number]\n",
        "    layer_name = layer.name\n",
        "    layer_type = type(layer).__name__\n",
        "    input_shape = layer.input_shape\n",
        "    output_shape = layer.output_shape\n",
        "\n",
        "    return {\n",
        "        \"Layer Name\": layer_name,\n",
        "        \"Layer Type\": layer_type,\n",
        "        \"Input Shape\": input_shape,\n",
        "        \"Output Shape\": output_shape\n",
        "    }\n",
        "\n",
        "\n",
        "def load_lottieurl(url):\n",
        "    r = requests.get(url)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "lottie_dreaming = load_lottieurl(\"https://lottie.host/b5551b7e-d91f-4bb1-b209-651ec55eb22e/mtLlUTl3iO.json\")\n",
        "\n",
        "#-------HEADER SECTION --------\n",
        "with st.container():\n",
        "    st.subheader(\"Hello User :wave:\")\n",
        "    st.title(\"Deep Dreaming\")\n",
        "    st.write(\"The future belongs to those who believe in the beauty of their DREAMS\")\n",
        "    st.write(\"[Learn More >](https://medium.com/hashworks/deep-dreaming-with-deep-learning-487835ebf315)\")\n",
        "\n",
        "\n",
        "with st.container():\n",
        "    st.write(\"---\")\n",
        "    left_column, right_column = st.columns(2)\n",
        "    with left_column:\n",
        "        st.header(\"About\")\n",
        "        st.write(\"##\")\n",
        "        st.write(\n",
        "            \"\"\"\n",
        "            Deep dreaming involves the generation of machine hallucinated images.\n",
        "            These wildly imaginative visuals are generated by a neural network that is actually a series of statistical learning models, powered by deceptively simple algorithms that are modelled after evolutionary processes.\n",
        "            Researchers have “trained” these networks by feeding them millions of images and gradually adjusting the network’s parameters until it gives the desired classification.\n",
        "\n",
        "            The outputs are not just meaningless patterns of neurons,\n",
        "            but depend on previous learning that the network undergoes representing data “attractors” — where some random neurons start to fire,\n",
        "            the weighted connections representing real output rapidly come to dominate the overall pattern of activity in the network, resulting in the pattern corresponding to a particular input.\n",
        "            \"\"\"\n",
        "        )\n",
        "        st.write(\"[Google Research >](https://blog.research.google/2015/06/inceptionism-going-deeper-into-neural.html)\")\n",
        "        with right_column:\n",
        "            st_lottie(lottie_dreaming, height=400, key=\"dreaming\")\n",
        "            # Add a button\n",
        "def first_page():\n",
        "\n",
        "    if st.button(\"Go to Image Processing Page\"):\n",
        "       st.session_state.page = \"Image Processing Page\"\n",
        "\n",
        "# Function to define the second page\n",
        "def image_processing_page():\n",
        "    st.title(\"Image Processing Page\")\n",
        "\n",
        "    uploaded_image = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        image = Image.open(uploaded_image)\n",
        "\n",
        "        # Display uploaded image in the center with width 1/3 of screen width\n",
        "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "        # Create a dropdown menu to select the model\n",
        "        selected_model = st.selectbox(\"Select a Model\", [\"InceptionV3\", \"ResNet50\",\"MobileNet\"])\n",
        "\n",
        "        # Load the selected model\n",
        "        if selected_model == \"InceptionV3\":\n",
        "            model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
        "        elif selected_model == \"ResNet50\":\n",
        "            model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "        elif selected_model == \"MobileNet\":\n",
        "            model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "        # Get the layer number from the user\n",
        "        num_layers = len(model.layers)\n",
        "        layer_number = st.number_input(f\"Enter the layer number (0 to {num_layers-1}): \", 0, num_layers-1, 0)\n",
        "\n",
        "        # Validate the user input\n",
        "        if layer_number < 0 or layer_number >= num_layers:\n",
        "            st.error(f\"Invalid layer number. Please enter a number between 0 and {num_layers-1}.\")\n",
        "        else:\n",
        "            layer_info = get_layer_info(model, layer_number)\n",
        "            # Display layer information\n",
        "            st.subheader(\"Selected Layer Information\")\n",
        "            for key, value in layer_info.items():\n",
        "                st.write(f\"**{key}:** {value}\")\n",
        "            layer_name = model.layers[layer_number].name\n",
        "            st.write(f\"You selected Layer: {layer_name}\")\n",
        "\n",
        "            # Generate the reversed original image from the DeepDream image\n",
        "            if selected_model == \"InceptionV3\":\n",
        "                original_image = deep_dream_inception(model, image, layer_name)\n",
        "            elif selected_model == \"ResNet50\":\n",
        "                original_image = deep_dream_resNet50(model, image, layer_name)\n",
        "            elif selected_model == \"MobileNet\":\n",
        "                original_image = deep_dream_mobileNet(model, image, layer_name)\n",
        "\n",
        "\n",
        "            # Display original and dream images side by side\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                st.image(image, caption=\"Original Image\", use_column_width=True)\n",
        "            with col2:\n",
        "                st.image(original_image, caption=\"Dream Image\", use_column_width=True)\n",
        "\n",
        "\n",
        "\n",
        "    if st.button(\"Back to First Page\"):\n",
        "        st.session_state.page = \"First Page\"\n",
        "\n",
        "\n",
        "# Set the initial page to \"First Page\"\n",
        "if \"page\" not in st.session_state:\n",
        "    st.session_state.page = \"First Page\"\n",
        "\n",
        "# Define the pages\n",
        "if st.session_state.page == \"First Page\":\n",
        "    first_page()\n",
        "elif st.session_state.page == \"Image Processing Page\":\n",
        "    image_processing_page()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14pUPWaGN88l",
        "outputId": "4338ae88-b192-4d70-ee27-d11e666cdc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting index.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mobileNet.py\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def deep_dream_mobileNet(model, image, layer_name, iterations=5, step_size=0.01, octave_scale=1.5, num_octaves=10):\n",
        "    img = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    img = tf.image.resize(img,(224,224))\n",
        "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
        "\n",
        "    # Reshape the input image to match the expected shape of the model\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Create a model that outputs the activation of the specified layer\n",
        "    layer_output = model.get_layer(layer_name).output\n",
        "    dream_model = tf.keras.Model(model.input, layer_output)\n",
        "\n",
        "    # Generate the DeepDream image\n",
        "    original_shape = img.shape[1:-1]\n",
        "    img = tf.image.resize(img, original_shape)\n",
        "\n",
        "    for _ in range(num_octaves):\n",
        "        # Generate details from the upsampled image\n",
        "        img_details = tf.Variable(img)\n",
        "        for _ in range(iterations):\n",
        "            with tf.GradientTape() as tape:\n",
        "                tape.watch(img_details)\n",
        "                outputs = dream_model(img_details)\n",
        "                loss = tf.reduce_mean(outputs)\n",
        "\n",
        "            gradients = tape.gradient(loss, img_details)\n",
        "            gradients /= tf.math.reduce_std(gradients) + 1e-8\n",
        "            img_details = tf.Variable(img_details + gradients * step_size)\n",
        "\n",
        "            img_details = tf.clip_by_value(img_details, -1, 1)\n",
        "\n",
        "        # Upscale the image for the next octave\n",
        "        img = tf.image.resize(img_details, original_shape)\n",
        "        step_size *= octave_scale\n",
        "\n",
        "    img = tf.clip_by_value(img, -1, 1)\n",
        "    img = tf.keras.preprocessing.image.array_to_img(img[0])\n",
        "    return img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVHr6MDVN9eh",
        "outputId": "79726d2d-d730-40da-b4a9-1a5891a770d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mobileNet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile resNet50.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def deep_dream_resNet50(model, image, layer_name, iterations=5, step_size=0.01, octave_scale=1.5, num_octaves=10):\n",
        "    img = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    #img = tf.image.resize(img,(299,299))\n",
        "    img = tf.keras.applications.resnet.preprocess_input(img)\n",
        "\n",
        "    # Reshape the input image to match the expected shape of the model\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Create a model that outputs the activation of the specified layer\n",
        "    layer_output = model.get_layer(layer_name).output\n",
        "    dream_model = tf.keras.Model(model.input, layer_output)\n",
        "\n",
        "    # Generate the DeepDream image\n",
        "    original_shape = img.shape[1:-1]\n",
        "    img = tf.image.resize(img, original_shape)\n",
        "\n",
        "    for _ in range(num_octaves):\n",
        "        # Generate details from the upsampled image\n",
        "        img_details = tf.Variable(img)\n",
        "        for _ in range(iterations):\n",
        "            with tf.GradientTape() as tape:\n",
        "                tape.watch(img_details)\n",
        "                outputs = dream_model(img_details)\n",
        "                loss = tf.reduce_mean(outputs)\n",
        "\n",
        "            gradients = tape.gradient(loss, img_details)\n",
        "            gradients /= tf.math.reduce_std(gradients) + 1e-8\n",
        "            img_details = tf.Variable(img_details + gradients * step_size)\n",
        "\n",
        "            img_details = tf.clip_by_value(img_details, -1, 1)\n",
        "\n",
        "        # Upscale the image for the next octave\n",
        "        img = tf.image.resize(img_details, original_shape)\n",
        "        step_size *= octave_scale\n",
        "\n",
        "    img = tf.clip_by_value(img, -1, 1)\n",
        "    img = tf.keras.preprocessing.image.array_to_img(img[0])\n",
        "    return img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqjsWL_IN96Y",
        "outputId": "cd9a5050-6230-4394-a4bc-ec2ff3287619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing resNet50.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile inceptionV3.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def deep_dream_inception(model, image, layer_name, iterations=20, step_size=0.01, octave_scale=1.5, num_octaves=3):\n",
        "    img = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "\n",
        "    # Reshape the input image to match the expected shape of the model\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Create a model that outputs the activation of the specified layer\n",
        "    layer_output = model.get_layer(layer_name).output\n",
        "    dream_model = tf.keras.Model(model.input, layer_output)\n",
        "\n",
        "    # Generate the DeepDream image\n",
        "    original_shape = img.shape[1:-1]\n",
        "    img = tf.image.resize(img, original_shape)\n",
        "\n",
        "    for _ in range(num_octaves):\n",
        "        # Generate details from the upsampled image\n",
        "        img_details = tf.Variable(img)\n",
        "        for _ in range(iterations):\n",
        "            with tf.GradientTape() as tape:\n",
        "                tape.watch(img_details)\n",
        "                outputs = dream_model(img_details)\n",
        "                loss = tf.reduce_mean(outputs)\n",
        "\n",
        "            gradients = tape.gradient(loss, img_details)\n",
        "            gradients /= tf.math.reduce_std(gradients) + 1e-8\n",
        "            img_details = tf.Variable(img_details + gradients * step_size)\n",
        "\n",
        "            img_details = tf.clip_by_value(img_details, -1, 1)\n",
        "\n",
        "        # Upscale the image for the next octave\n",
        "        img = tf.image.resize(img_details, original_shape)\n",
        "        step_size *= octave_scale\n",
        "\n",
        "    img = tf.clip_by_value(img, -1, 1)\n",
        "    img = tf.keras.preprocessing.image.array_to_img(img[0])\n",
        "    return img\n",
        "\n",
        "# # Load the InceptionV3 model\n",
        "# model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# # Get the number of layers in the model\n",
        "# num_layers = len(model.layers)\n",
        "\n",
        "# # Get the layer number from user input\n",
        "# layer_number = int(input(f\"Enter the layer number (0 to {num_layers-1}): \"))\n",
        "\n",
        "# # Validate the user input\n",
        "# if layer_number < 0 or layer_number >= num_layers:\n",
        "#     print(f\"Invalid layer number. Please enter a number between 0 and {num_layers-1}.\")\n",
        "#     exit()\n",
        "\n",
        "# # Load an example image\n",
        "# image_path = 'mona.jpg'\n",
        "# image = tf.keras.preprocessing.image.load_img(image_path)       #, target_size=(675, 1200)\n",
        "\n",
        "# # Specify the layer name based on the user input\n",
        "# layer_name = model.layers[layer_number].name\n",
        "\n",
        "# # Generate the DeepDream image for the selected layer\n",
        "# dream_image = deep_dream(model, image, layer_name)\n",
        "\n",
        "# # Display the original image and the DeepDream image\n",
        "# # fig, axes = plt.subplots(1, 2)\n",
        "# # axes[0].imshow(image)\n",
        "# # axes[0].set_title('Original Image')\n",
        "# # axes[1].imshow(dream_image)\n",
        "# # axes[1].set_title('DeepDream Image (Layer: ' + layer_name + ')')\n",
        "# # plt.show()\n",
        "\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # Adjust the figsize as needed\n",
        "\n",
        "# axes[0].imshow(image)\n",
        "# axes[0].set_title('Original Image')\n",
        "# axes[1].imshow(dream_image)\n",
        "# axes[1].set_title('DeepDream Image (Layer: ' + layer_name + ')')\n",
        "\n",
        "# plt.tight_layout()  # Optional: Adjust the layout for better spacing\n",
        "# plt.show()\n",
        "# #dream_image.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC4TgpR4N-5h",
        "outputId": "83b68129-28cd-40b3-ee4a-85972ad56eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inceptionV3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run index.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "huOrxRmWN_gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUNglfxbawkq",
        "outputId": "e601815f-f181-4600-eb96-2c05ac763ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.488s\n",
            "your url is: https://nine-feet-stop.loca.lt\n"
          ]
        }
      ]
    }
  ]
}